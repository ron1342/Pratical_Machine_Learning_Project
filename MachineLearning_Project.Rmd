---
title: "MachineLearning_Project"
author: "Ronald Armando"
date: "4/26/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Data Loading

## Dataset Overview
The training data for this project is available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project can be found here: http://groupware.les.inf.puc-rio.br/har.

A short description of the datasets content from the authors’ website:

“Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes. Participants were supervised by an experienced weight lifter to make sure the execution complied to the manner they were supposed to simulate. The exercises were performed by six male participants aged between 20-28 years, with little weight lifting experience. We made sure that all participants could easily simulate the mistakes in a safe and controlled manner by using a relatively light dumbbell (1.25kg)."

## Getting and loading the data
We first upload the R libraries that are necessary for the complete analysis.

```{r}
rm(list=ls())               
library(knitr)
library(caret)
library(randomForest)
library(corrplot)
library(rpart)
library(rpart.plot)
library(rattle)


set.seed(12345)

#Set URL for data download
train_Url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_Url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

#Download datasets
training <- read.csv(url(train_Url), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(test_Url), na.strings=c("NA","#DIV/0!",""))

# Create a partition with the training dataset - 70% Training Data & 30% Test Data
inTrain  <- createDataPartition(training$classe, p=0.7, list=FALSE)
TrainD <- training[inTrain, ]
TestD  <- training[-inTrain, ]
```

Let's see the dimensions for both training and test sets and have an overview of the dataset

```{r}
dim(TrainD)
dim(TestD)

str(TrainD)
```
## Cleaning the data

We can see from the previous step that both datasets have 160 variables, and also it is possible to see that many of those variables have NA values. The Near Zero variance (NZV) variables are also removed and the ID variables as well.

```{r}
# Remove variables with Nearly Zero Variance
NZV <- nearZeroVar(TrainD)
TrainD <- TrainD[, -NZV]
TestD  <- TestD[, -NZV]
dim(TrainD)
dim(TestD)
```

```{r}
# remove variables that are mostly NA
AllNAval    <- sapply(TrainD, function(x) mean(is.na(x))) > 0.95
TrainD <- TrainD[, AllNAval==FALSE]
TestD  <- TestD[, AllNAval==FALSE]
dim(TrainD)
dim(TestD)
```

Now we need to remove the identification only variables, which correspond to columns 1 to 5

```{r}
TrainD <- TrainD[, -(1:5)]
TestD  <- TestD[, -(1:5)]
dim(TrainD)
dim(TestD)
```

After all these steps, we see that we were able to reduce the number of variables from 160 to 54.

## Correlation Analysis

```{r corrplot, echo = FALSE}
corMatrix <- cor(TrainD[, -54])
corrplot(corMatrix, order = "FPC", method = "ellipse", type = "upper", 
         tl.srt = 45)
```


The highly correlated variables are shown in dark colors in the graph above: blue if they are positively correlated and red if they are negativily correlated.


# Prediction Model Building

Three methods will be applied to model the regressions and the best one, with higher accuracy when applied to the Test dataset, will be used for the quiz predictions. 
The methods are: Random Forests, Decision Tree and Generalized Boosted Model.
At the end of each analysis, a confusion matrix will be plotted to better visualize the accuracy of the each model.

## Random Forest

```{r}
# model fit
set.seed(12345)
controlRF <- trainControl(method="cv", number=3, verboseIter=FALSE)
modFitRF <- train(classe ~ ., data=TrainD, method="rf",
                          trControl=controlRF)
modFitRF$finalModel
```

```{r}
# prediction on Test dataset
predictRF <- predict(modFitRF, newdata=TestD)
confMatRF <- confusionMatrix(predictRF, TestD$classe)
confMatRF
```

```{r}
# plot matrix results
plot(confMatRF$table, col = confMatRF$byClass, 
     main = paste("Random Forest - Accuracy =",
                  round(confMatRF$overall['Accuracy'], 4)))
```

## Decision Trees

```{r}
# Model Fit
set.seed(12345)
modFitDT <- rpart(classe ~ ., data=TrainD, method="class")
rpart.plot(modFitDT, box.palette = "GnBu")
```

```{r}
predictDT <- predict(modFitDT, newdata=TestD, type="class")
confMatDT <- confusionMatrix(predictDT, TestD$classe)
confMatDT
```

```{r}
# Plot matrix results
plot(confMatDT$table, col = confMatDT$byClass, 
     main = paste("Decision Tree - Accuracy =",
                  round(confMatDT$overall['Accuracy'], 4)))
```

## Generalized Boosted Model

```{r}
set.seed(12345)
controlGbm <- trainControl(method = "repeatedcv", number = 5, repeats = 1)
modFitGbm  <- train(classe ~ ., data=TrainD, method = "gbm",
                    trControl = controlGbm, verbose = FALSE)
modFitGbm$finalModel
```

```{r}
predictGbm <- predict(modFitGbm, newdata=TestD)
confMatGbm <- confusionMatrix(predictGbm, TestD$classe)
confMatGbm
```

```{r}
# Plot matrix results
plot(confMatGbm$table, col = confMatGbm$byClass, 
     main = paste("GBM - Accuracy =", round(confMatGbm$overall['Accuracy'], 4)))
```

# Applying Best Model to Test Data

The accuracy of the 3 regression modeling methods are:

Random Forest : 0.9964
Decision Tree : 0.7368
GBM : 0.9857

Random Forest model will be applied to predict the 20 quiz results, as follows:

```{r}
predictTEST <- predict(modFitRF, newdata=testing)
predictTEST
```


